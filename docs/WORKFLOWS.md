# Workflows

## Overview

Metarr operates through 6 core workflows that handle all media processing scenarios. These workflows are designed for efficiency and automation while preserving user control.

**Core Principle**: "Automate Everything, Override Anything"
- 95% webhook automation
- 5% manual fixes when needed
- Field locking preserves user edits

---

## Implementation Status

- âœ… **[Implemented]** - Webhook receiver infrastructure
- âœ… **[Implemented]** - Job queue processing
- âœ… **[Implemented]** - Database schema for all workflows
- ğŸ“‹ **[Planned]** - Workflow 1: New media webhook processing
- ğŸ“‹ **[Planned]** - Workflow 2: Upgrade handling with playback state
- ğŸ“‹ **[Planned]** - Workflow 3: Manual library scan
- ğŸ“‹ **[Planned]** - Workflow 4: Manual asset replacement
- ğŸ“‹ **[Planned]** - Workflow 5: Delete webhook (trash day)
- ğŸ“‹ **[Planned]** - Workflow 6: Unidentified media identification

---

## Workflow 1: Webhook - New Media

**Trigger**: Radarr/Sonarr sends "Download" or "Import" webhook

**Purpose**: Fully automated processing of new media from *arr stack

### Flow Diagram

```
Webhook Received
    â†“
Parse Webhook Payload
    â†“
Check if Movie Exists (by provider ID)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NEW MEDIA   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Create Job (Priority 1 - Critical)
    â†“
JOB PROCESSING:
â”‚
â”œâ”€ 1. Create Database Record
â”‚   - Extract: title, year, file_path, provider IDs
â”‚   - Status: identified
â”‚   - Priority: 1 (immediate enrichment)
â”‚
â”œâ”€ 2. FFprobe Analysis
â”‚   - Extract: video streams (codec, resolution, HDR)
â”‚   - Extract: audio streams (codec, language, channels)
â”‚   - Extract: subtitle streams (embedded + external .srt)
â”‚   - Store in: video_streams, audio_streams, subtitle_streams
â”‚
â”œâ”€ 3. Provider Enrichment (TMDB/TVDB/etc)
â”‚   - Fetch: metadata (plot, rating, release date, runtime)
â”‚   - Fetch: cast & crew (actors, directors, writers)
â”‚   - Fetch: asset URLs (posters, fanart, logos, trailers)
â”‚   - Store in: normalized tables (actors, crew, genres, studios)
â”‚   - Update: identification_status = 'enriched'
â”‚
â”œâ”€ 4. Asset Download (Concurrent)
â”‚   - Download all asset types from providers
â”‚   - Calculate: SHA256 hash, perceptual hash (images)
â”‚   - Store in: /cache/assets/{ab}/{cd}/{hash}.ext
â”‚   - Deduplicate: Check if hash exists in cache_assets
â”‚   - Create: cache_assets record (if new)
â”‚   - Link: asset_references (entity â†’ cache_asset)
â”‚   - Update: movie.poster_id, fanart_id, etc.
â”‚
â”œâ”€ 5. Write Library Assets
â”‚   - Copy from cache â†’ library directory
â”‚   - Naming: Kodi convention (moviename-poster.jpg, moviename-fanart.jpg)
â”‚   - Generate: NFO file with all metadata
â”‚
â””â”€ 6. Notify Media Players
    - Translate: Metarr path â†’ Player path (via path_mappings)
    - Send: Library update notification to all Kodi groups
    - Trigger: Library scan for new item

COMPLETE
```

### Code Example

```typescript
async function handleNewMediaWebhook(webhook: WebhookPayload): Promise<void> {
  // Create critical priority job
  const jobId = await jobQueue.add({
    type: 'webhook',
    priority: 1,
    payload: {
      action: 'new_media',
      movieId: webhook.movie.tmdbId,
      filePath: webhook.movie.path,
      title: webhook.movie.title,
      year: webhook.movie.year
    }
  });

  // Job processor handles the rest
  await jobQueue.process(jobId);
}

async function processNewMediaJob(job: Job): Promise<void> {
  // Step 1: Create database record
  const movie = await db.movies.create({
    library_id: 1,
    file_path: job.payload.filePath,
    title: job.payload.title,
    year: job.payload.year,
    tmdb_id: job.payload.movieId,
    identification_status: 'identified',
    enrichment_priority: 1
  });

  // Step 2: FFprobe
  const streams = await ffprobe(job.payload.filePath);
  await storeStreams(movie.id, streams);

  // Step 3: Provider enrichment
  const metadata = await tmdb.getMovie(job.payload.movieId);
  await enrichMovie(movie.id, metadata);

  // Step 4: Download assets
  await downloadAssets(movie.id, metadata.images);

  // Step 5: Write library files
  await writeNFO(movie.id);
  await copyAssetsToLibrary(movie.id);

  // Step 6: Notify players
  await notifyKodiGroups('library.scan', { movieId: movie.id });
}
```

### Timing

- **Total Duration**: 10-30 seconds (depends on asset count)
  - Database + FFprobe: 1-2 seconds
  - Provider API: 1-3 seconds
  - Asset downloads: 5-20 seconds (concurrent)
  - NFO + Library writes: 1-2 seconds
  - Kodi notification: 1 second

## Workflow 2: Webhook - Upgrade

**Trigger**: Radarr sends "MovieFileDelete" followed by "Download" webhook

**Purpose**: Handle quality upgrades while preserving assets and playback state

### Flow Diagram

```
MovieFileDelete Webhook
    â†“
Check if Movie is Currently Playing
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PLAYING â†’ CAPTURE  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Query Kodi: Get playback position
Store in: playback_state table
    â†“
Download Webhook (New File)
    â†“
Update Movie Record
â”‚
â”œâ”€ Update: file_path (new location)
â”œâ”€ Update: file_size, file_hash
â”œâ”€ Re-run: FFprobe (new streams)
â”œâ”€ Keep: All metadata (no re-enrichment)
â”œâ”€ Keep: All assets (already in cache)
â”‚
â””â”€ Copy Assets to New Location
    - Source: cache (SHA256 hash)
    - Destination: new movie directory
    - Naming: Kodi convention

Update NFO (new file path)
    â†“
Notify Kodi Groups
    â†“
Check for Playback State
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HAS STATE â†’ RESTORE  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Resume Playback:
- Same position
- Same player
- Notify user: "Upgrade complete, resuming playback"
```

### Code Example

```typescript
async function handleMovieFileDeleteWebhook(webhook: WebhookPayload): Promise<void> {
  const movie = await db.movies.findByTmdbId(webhook.movie.tmdbId);

  // Check if currently playing
  const playbackState = await kodi.getPlaybackState(movie.id);

  if (playbackState) {
    // Capture current position
    await db.playback_state.create({
      media_player_id: playbackState.playerId,
      entity_type: 'movie',
      entity_id: movie.id,
      file_path: movie.file_path,
      position_seconds: playbackState.position,
      total_seconds: playbackState.total,
      position_percentage: (playbackState.position / playbackState.total) * 100
    });

    // Stop playback
    await kodi.stopPlayback(playbackState.playerId);
  }
}

async function handleUpgradeDownloadWebhook(webhook: WebhookPayload): Promise<void> {
  const movie = await db.movies.findByTmdbId(webhook.movie.tmdbId);

  // Update file info only (keep all metadata and assets)
  await db.movies.update(movie.id, {
    file_path: webhook.movie.path,
    file_size: webhook.movie.size,
    updated_at: new Date()
  });

  // Re-analyze streams (may have changed)
  const streams = await ffprobe(webhook.movie.path);
  await updateStreams(movie.id, streams);

  // Copy assets from cache to new location
  await copyAssetsToLibrary(movie.id);

  // Update NFO
  await writeNFO(movie.id);

  // Notify players
  await notifyKodiGroups('library.scan', { movieId: movie.id });

  // Check for playback state
  const playbackState = await db.playback_state.findLatest(movie.id);

  if (playbackState && !playbackState.restored_at) {
    // Wait for library scan to complete (5 seconds)
    await sleep(5000);

    // Resume playback
    await kodi.play(playbackState.media_player_id, {
      file: translatePath(movie.file_path, playbackState.media_player_id),
      resume: {
        position: playbackState.position_seconds,
        percentage: playbackState.position_percentage
      }
    });

    // Mark as restored
    await db.playback_state.update(playbackState.id, {
      restored_at: new Date()
    });

    // Notify user
    await kodi.showNotification(playbackState.media_player_id, {
      title: 'Upgrade Complete',
      message: `${movie.title} upgraded and resumed`,
      image: movie.poster_path
    });
  }
}
```

### Timing

- **Upgrade Duration**: 5-10 seconds
  - Playback capture: <1 second
  - Database update: <1 second
  - FFprobe: 1-2 seconds
  - Asset copy: 1-3 seconds
  - NFO write: <1 second
  - Playback restore: 5 seconds (wait for scan)

## Workflow 3: Manual Library Scan

**Trigger**: User clicks "Scan Library" or scheduled scan runs

**Purpose**: Discover new files, remove deleted files, realign metadata

### Flow Diagram

```
Scan Initiated
    â†“
Create Scan Job (Priority 7 - Low)
    â†“
Read Library Configuration
    â†“
Filesystem Walk
â”‚
â”œâ”€ For each media file:
â”‚   â”‚
â”‚   â”œâ”€ Check Database (by file_path)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€ EXISTS â†’ Compare file_hash
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€ SAME â†’ Skip (no changes)
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€ DIFFERENT â†’ File replaced
â”‚   â”‚   â”‚       - Delete old streams
â”‚   â”‚   â”‚       - Re-run FFprobe
â”‚   â”‚   â”‚       - Keep metadata (unless locked)
â”‚   â”‚   â”‚       - Update file_hash
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€ NOT EXISTS â†’ New file
â”‚   â”‚       - Parse filename (title, year)
â”‚   â”‚       - Create database record
â”‚   â”‚       - Status: unidentified
â”‚   â”‚       - Add to enrichment queue
â”‚   â”‚
â”‚   â””â”€ Check for sidecar files
â”‚       - NFO file â†’ Parse for provider IDs
â”‚       - Subtitle files â†’ Link to movie
â”‚       - Image files â†’ Import to cache
â”‚
â””â”€ Check for deleted files
    - Database records not found in filesystem
    - Set: deleted_at = NOW() + 30 days (soft delete)

Scan Complete
    â†“
Process Unidentified Files
â”‚
â”œâ”€ Search Provider (TMDB/TVDB)
â”‚   - Query: title + year
â”‚   - Match threshold: 85% confidence
â”‚   â”‚
â”‚   â”œâ”€ MATCH FOUND â†’ Update record
â”‚   â”‚   - Set: provider IDs
â”‚   â”‚   - Status: identified
â”‚   â”‚   - Add to enrichment queue (priority 5)
â”‚   â”‚
â”‚   â””â”€ NO MATCH â†’ Manual intervention
â”‚       - Status: unidentified
â”‚       - User notified via UI
â”‚
â””â”€ Process Enrichment Queue
    - Background job processes identified media
    - Lower priority (5) than webhooks (1)
```

### Code Example

```typescript
async function scanLibrary(libraryId: number): Promise<ScanResult> {
  const library = await db.libraries.findById(libraryId);
  const scanJob = await db.scan_jobs.create({
    library_id: libraryId,
    scan_type: 'full',
    status: 'running',
    started_at: new Date()
  });

  const stats = {
    total: 0,
    added: 0,
    updated: 0,
    removed: 0,
    unidentified: 0
  };

  // Walk filesystem
  const files = await walkDirectory(library.path, ['.mkv', '.mp4', '.avi']);
  stats.total = files.length;

  for (const file of files) {
    const fileHash = await calculateHash(file.path);
    const existing = await db.movies.findByPath(file.path);

    if (existing) {
      // Check if file changed
      if (existing.file_hash !== fileHash) {
        await updateMovie(existing.id, file, fileHash);
        stats.updated++;
      }
    } else {
      // New file
      const parsed = parseFilename(file.name);
      const movie = await db.movies.create({
        library_id: libraryId,
        file_path: file.path,
        file_name: file.name,
        file_size: file.size,
        file_hash: fileHash,
        title: parsed.title,
        year: parsed.year,
        identification_status: 'unidentified',
        enrichment_priority: 5
      });

      stats.added++;

      // Try to identify
      const match = await searchTMDB(parsed.title, parsed.year);
      if (match && match.confidence > 0.85) {
        await db.movies.update(movie.id, {
          tmdb_id: match.id,
          imdb_id: match.imdb_id,
          identification_status: 'identified'
        });

        // Add to enrichment queue
        await jobQueue.add({
          type: 'enrichment',
          priority: 5,
          payload: { movieId: movie.id }
        });
      } else {
        stats.unidentified++;
      }
    }
  }

  // Check for deleted files
  const allMovies = await db.movies.findByLibrary(libraryId);
  const filePaths = new Set(files.map(f => f.path));

  for (const movie of allMovies) {
    if (!filePaths.has(movie.file_path) && !movie.deleted_at) {
      await db.movies.update(movie.id, {
        deleted_at: addDays(new Date(), 30)
      });
      stats.removed++;
    }
  }

  // Update scan job
  await db.scan_jobs.update(scanJob.id, {
    status: 'completed',
    completed_at: new Date(),
    total_items: stats.total,
    added_items: stats.added,
    updated_items: stats.updated,
    removed_items: stats.removed
  });

  return stats;
}
```

### Timing

- **Scan Duration**: Depends on library size
  - Small (100 movies): 1-2 minutes
  - Medium (1000 movies): 10-15 minutes
  - Large (5000 movies): 30-60 minutes
- **Per File**: ~1-2 seconds (hash calculation + database lookup)

## Workflow 4: Manual Asset Replacement

**Trigger**: User uploads custom asset or selects different provider image

**Purpose**: Override automated asset selection with user preference

### Flow Diagram

```
User Action: "Replace Poster"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UPLOAD LOCAL FILE   â”‚
â”‚ or                  â”‚
â”‚ SELECT FROM PROVIDERâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
IF UPLOAD:
â”‚
â”œâ”€ Validate Image
â”‚   - Check: file type (jpg, png)
â”‚   - Check: dimensions (min 1000x1500)
â”‚   - Check: file size (max 10MB)
â”‚
â”œâ”€ Process Image
â”‚   - Calculate: SHA256 hash
â”‚   - Calculate: perceptual hash
â”‚   - Check: Duplicate in cache (by hash)
â”‚
â”œâ”€ Store in Cache
â”‚   - Path: /cache/assets/{ab}/{cd}/{hash}.jpg
â”‚   - Create: cache_assets record
â”‚   - Source: 'user'
â”‚
â””â”€ Link to Movie
    - Update: movie.poster_id
    - Set: movie.poster_locked = true
    - Create: asset_references record

IF PROVIDER:
â”‚
â”œâ”€ Download from URL
â”‚   - Process same as upload
â”‚   - Source: 'provider'
â”‚
â””â”€ Link to Movie (same as above)

Copy to Library
    â†“
Update NFO
    â†“
Set Field Lock
- poster_locked = true
- Prevents future automation from changing
    â†“
Notify Media Players
    â†“
Activity Log
- Event: 'asset.replaced'
- Description: "User replaced poster for {title}"
```

### Code Example

```typescript
async function replaceAsset(
  movieId: number,
  assetType: string,
  source: 'upload' | 'provider',
  data: Buffer | string
): Promise<void> {
  let imageBuffer: Buffer;

  if (source === 'upload') {
    imageBuffer = data as Buffer;
  } else {
    // Download from provider URL
    imageBuffer = await downloadImage(data as string);
  }

  // Validate
  const metadata = await sharp(imageBuffer).metadata();
  if (metadata.width < 1000 || metadata.height < 1500) {
    throw new Error('Image too small (min 1000x1500)');
  }

  // Generate UUID for filename
  const uuid = crypto.randomUUID();

  // Calculate hashes
  const sha256Hash = crypto.createHash('sha256').update(imageBuffer).digest('hex');
  const perceptualHash = await calculatePerceptualHash(imageBuffer);

  // Check for visual duplicate (by perceptual hash)
  const existingImages = await db.query(`
    SELECT * FROM cache_image_files
    WHERE entity_type = 'movie' AND entity_id = ? AND image_type = ?
  `, [movieId, assetType]);

  for (const existing of existingImages) {
    const similarity = comparePerceptualHashes(perceptualHash, existing.perceptual_hash);
    if (similarity >= 0.90) {
      throw new Error('Visually identical image already exists');
    }
  }

  // Store in cache with UUID naming
  const cachePath = `/data/cache/images/movie/${movieId}/${uuid}.jpg`;
  await fs.mkdir(path.dirname(cachePath), { recursive: true });
  await fs.writeFile(cachePath, imageBuffer);

  // Create cache record
  const cacheResult = await db.execute(`
    INSERT INTO cache_image_files (
      entity_type, entity_id, file_path, file_name, file_size,
      file_hash, perceptual_hash, image_type, width, height, format,
      source_type, is_locked
    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 1)
  `, ['movie', movieId, cachePath, `${uuid}.jpg`, imageBuffer.length,
      sha256Hash, perceptualHash, assetType, metadata.width, metadata.height,
      metadata.format, source === 'upload' ? 'user' : 'provider']);

  const cacheFileId = cacheResult.insertId;

  // Get movie
  const movie = await db.movies.findById(movieId);

  // Update movie FK column (e.g., poster_id)
  await db.movies.update(movieId, {
    [`${assetType}_id`]: cacheFileId,
    [`${assetType}_locked`]: true
  });

  // Copy to library (publish)
  const libraryPath = await copyAssetToLibrary(movieId, assetType, cachePath);

  // Create library record
  await db.execute(`
    INSERT INTO library_image_files (cache_file_id, file_path)
    VALUES (?, ?)
    ON CONFLICT(file_path) DO UPDATE SET cache_file_id = excluded.cache_file_id
  `, [cacheFileId, libraryPath]);

  // Update NFO
  await writeNFO(movieId);

  // Notify players
  await notifyKodiGroups('library.scan', { movieId });

  // Log activity
  await db.activity_log.create({
    event_type: 'asset.replaced',
    severity: 'info',
    entity_type: 'movie',
    entity_id: movieId,
    description: `User replaced ${assetType} for ${movie.title}`
  });
}
```

### Timing

- **Upload**: 2-5 seconds
  - Image processing: 1-2 seconds
  - Cache storage: <1 second
  - Database updates: <1 second
  - Library copy: <1 second
  - NFO write: <1 second

## Workflow 5: Delete Webhook (Trash Day)

**Trigger**: Radarr sends "MovieDelete" webhook

**Purpose**: Soft delete with 30-day recovery period

### Flow Diagram

```
MovieDelete Webhook
    â†“
Find Movie Record (by provider ID)
    â†“
Soft Delete
- Set: deleted_at = NOW() + 30 days
- Status: Visible in "Trash" UI
    â†“
User Has 30 Days to:
â”‚
â”œâ”€ RESTORE â†’ Clear deleted_at
â”‚   - Movie returns to library
â”‚   - All assets intact
â”‚   - No re-download needed
â”‚
â””â”€ DO NOTHING â†’ Auto-delete after 30 days

Scheduled Job (Daily):
â”‚
â””â”€ Find Expired Records
    - Query: deleted_at < NOW()
    â”‚
    â””â”€ For each expired movie:
        â”‚
        â”œâ”€ Delete database record
        â”‚   - Cascade: all relationships
        â”‚   - Cascade: stream details
        â”‚   - Cascade: asset references
        â”‚
        â”œâ”€ Decrement cache reference counts
        â”‚   - For each linked asset
        â”‚   - If ref_count = 0 â†’ mark orphaned
        â”‚
        â””â”€ Delete library files (NFO, assets)

Cache Cleanup (Weekly):
â”‚
â””â”€ Find orphaned assets
    - Query: reference_count = 0 AND created_at < NOW() - 90 days
    â”‚
    â””â”€ Delete physical files
        - Remove from /cache/assets/
        - Delete cache_assets record
```

### Code Example

```typescript
async function handleMovieDeleteWebhook(webhook: WebhookPayload): Promise<void> {
  const movie = await db.movies.findByTmdbId(webhook.movie.tmdbId);

  if (!movie) {
    return; // Already deleted
  }

  // Soft delete (30-day grace period)
  await db.movies.update(movie.id, {
    deleted_at: addDays(new Date(), 30)
  });

  await db.activity_log.create({
    event_type: 'movie.deleted',
    severity: 'warning',
    entity_type: 'movie',
    entity_id: movie.id,
    description: `Movie soft-deleted via webhook: ${movie.title}. Recoverable for 30 days.`,
    metadata: JSON.stringify(webhook)
  });
}

async function restoreMovie(movieId: number): Promise<void> {
  const movie = await db.movies.findById(movieId);

  if (!movie.deleted_at) {
    throw new Error('Movie is not deleted');
  }

  // Restore
  await db.movies.update(movieId, {
    deleted_at: null
  });

  await db.activity_log.create({
    event_type: 'movie.restored',
    severity: 'success',
    entity_type: 'movie',
    entity_id: movieId,
    description: `Movie restored from trash: ${movie.title}`
  });
}

// Scheduled job (runs daily)
async function permanentlyDeleteExpired(): Promise<void> {
  const expired = await db.movies.findExpired();

  for (const movie of expired) {
    // Get all linked assets before deletion
    const assets = await db.asset_references.findByEntity('movie', movie.id);

    // Delete movie (cascades to all relationships)
    await db.movies.delete(movie.id);

    // Decrement asset reference counts
    for (const asset of assets) {
      await decrementAssetReference(asset.cache_asset_id);
    }

    // Delete library files
    await deleteLibraryFiles(movie.file_path);

    await db.activity_log.create({
      event_type: 'movie.permanently_deleted',
      severity: 'warning',
      entity_type: 'movie',
      entity_id: movie.id,
      description: `Movie permanently deleted after grace period: ${movie.title}`
    });
  }
}

// Scheduled job (runs weekly)
async function cleanupOrphanedAssets(): Promise<void> {
  const orphaned = await db.cache_assets.find({
    reference_count: 0,
    created_at: { $lt: subDays(new Date(), 90) }
  });

  for (const asset of orphaned) {
    // Delete physical file
    await fs.unlink(asset.file_path);

    // Delete database record
    await db.cache_assets.delete(asset.id);
  }

  await db.activity_log.create({
    event_type: 'cache.cleanup',
    severity: 'info',
    description: `Cleaned up ${orphaned.length} orphaned assets`
  });
}
```

## Workflow 6: Unidentified Media

**Trigger**: Library scan finds file that can't be automatically matched

**Purpose**: User intervention to identify media

### Flow Diagram

```
Scan Finds Unknown File
    â†“
Parse Filename
- Extract: title, year (best guess)
- Status: unidentified
    â†“
Search Provider (Auto-attempt)
- Query: TMDB with title + year
- Confidence threshold: 85%
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MATCH < 85%    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
User Notification
- UI: "Unidentified Media" badge
- List: All unidentified files
    â†“
User Actions:
â”‚
â”œâ”€ 1. SEARCH MANUALLY
â”‚   - User enters: title, year
â”‚   - UI shows: provider results
â”‚   - User selects: correct match
â”‚   - Update: provider IDs
â”‚   - Status: identified
â”‚   - Trigger: Workflow 1 (enrichment)
â”‚
â”œâ”€ 2. ENTER METADATA MANUALLY
â”‚   - User fills form: title, plot, cast, etc.
â”‚   - Upload: custom assets
â”‚   - Status: enriched
â”‚   - Lock: all fields (prevent automation)
â”‚
â””â”€ 3. IGNORE
    - Mark: identification_status = 'ignored'
    - Hide from UI
    - Skip in future scans
```

### Code Example

```typescript
async function identifyMovie(movieId: number, tmdbId: number): Promise<void> {
  const movie = await db.movies.findById(movieId);

  // Update with provider ID
  await db.movies.update(movieId, {
    tmdb_id: tmdbId,
    identification_status: 'identified',
    enrichment_priority: 2 // High priority (user action)
  });

  // Add to enrichment queue
  await jobQueue.add({
    type: 'enrichment',
    priority: 2,
    payload: { movieId }
  });

  await db.activity_log.create({
    event_type: 'movie.identified',
    severity: 'success',
    entity_type: 'movie',
    entity_id: movieId,
    description: `User identified movie: ${movie.title} â†’ TMDB ${tmdbId}`
  });
}

async function manuallyEnrichMovie(
  movieId: number,
  metadata: ManualMetadata
): Promise<void> {
  // Update all fields
  await db.movies.update(movieId, {
    ...metadata,
    identification_status: 'enriched',

    // Lock all manually entered fields
    title_locked: true,
    plot_locked: true,
    year_locked: true,
    // ... lock all provided fields
  });

  // Handle manual cast/crew
  if (metadata.actors) {
    for (const actorName of metadata.actors) {
      const actor = await db.actors.findOrCreate(actorName);
      await db.movie_actors.create({
        movie_id: movieId,
        actor_id: actor.id
      });
    }

    await db.movies.update(movieId, { actors_locked: true });
  }

  // Handle manual assets
  if (metadata.customAssets) {
    for (const [type, file] of Object.entries(metadata.customAssets)) {
      await replaceAsset(movieId, type, 'upload', file);
    }
  }

  await db.activity_log.create({
    event_type: 'movie.manually_enriched',
    severity: 'success',
    entity_type: 'movie',
    entity_id: movieId,
    description: `User manually enriched movie with custom metadata`
  });
}
```

## Supporting Processes

### Job Queue Processing

```typescript
class JobQueue {
  async process(): Promise<void> {
    while (true) {
      // Get next job (priority order)
      const job = await db.job_queue.findNext();

      if (!job) {
        await sleep(1000);
        continue;
      }

      // Mark as running
      await db.job_queue.update(job.id, {
        status: 'running',
        started_at: new Date()
      });

      try {
        // Route to handler
        switch (job.job_type) {
          case 'webhook':
            await processWebhookJob(job);
            break;
          case 'enrichment':
            await processEnrichmentJob(job);
            break;
          case 'scan':
            await processScanJob(job);
            break;
        }

        // Mark complete
        await db.job_queue.update(job.id, {
          status: 'completed',
          completed_at: new Date()
        });

      } catch (error) {
        // Handle failure
        if (job.retry_count < job.max_retries) {
          await db.job_queue.update(job.id, {
            status: 'pending',
            retry_count: job.retry_count + 1,
            next_retry_at: addMinutes(new Date(), 5),
            error_message: error.message
          });
        } else {
          await db.job_queue.update(job.id, {
            status: 'failed',
            error_message: error.message,
            completed_at: new Date()
          });
        }
      }
    }
  }
}
```

### Path Translation

```typescript
async function translatePath(
  metarrPath: string,
  mediaPlayerGroupId: number
): Promise<string> {
  const mappings = await db.path_mappings.findByGroup(mediaPlayerGroupId);

  for (const mapping of mappings) {
    if (metarrPath.startsWith(mapping.metarr_path)) {
      return metarrPath.replace(mapping.metarr_path, mapping.player_path);
    }
  }

  throw new Error(`No path mapping found for: ${metarrPath}`);
}
```

### Asset Reference Counting

**Note**: Current implementation uses foreign key tracking via `library_*_files.cache_file_id`.
Reference counting for garbage collection is [Planned].

```typescript
// Current approach: Find orphaned cache files via LEFT JOIN
async function findOrphanedCacheFiles(): Promise<CacheImageFile[]> {
  return await db.query(`
    SELECT cif.*
    FROM cache_image_files cif
    LEFT JOIN library_image_files lif ON lif.cache_file_id = cif.id
    WHERE lif.id IS NULL
      AND cif.discovered_at < datetime('now', '-90 days')
      AND cif.is_locked = 0
  `);
}

// Planned: Reference counting column for faster queries
async function incrementAssetReference(cacheFileId: number): Promise<void> {
  await db.execute(`
    UPDATE cache_image_files
    SET last_verified_at = CURRENT_TIMESTAMP
    WHERE id = ?
  `, [cacheFileId]);
}

async function decrementAssetReference(cacheFileId: number): Promise<void> {
  // No-op in current implementation (handled by foreign key CASCADE)
  // Planned: Decrement reference_count column when implemented
}
```

## Error Handling

### Provider API Failures

```typescript
async function enrichMovie(movieId: number): Promise<void> {
  try {
    const movie = await db.movies.findById(movieId);
    const metadata = await tmdb.getMovie(movie.tmdb_id);

    // Process metadata...

  } catch (error) {
    if (error instanceof RateLimitError) {
      // Retry later
      throw new RetryableError('Rate limit exceeded', 300); // 5 min
    } else if (error instanceof NetworkError) {
      // Retry soon
      throw new RetryableError('Network error', 60); // 1 min
    } else {
      // Fatal error
      await db.movies.update(movieId, {
        identification_status: 'error'
      });
      throw error;
    }
  }
}
```

### Asset Download Failures

```typescript
async function downloadAsset(url: string): Promise<Buffer> {
  const maxRetries = 3;

  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(url, { timeout: 30000 });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      return await response.buffer();

    } catch (error) {
      if (attempt === maxRetries) {
        throw error;
      }

      await sleep(attempt * 1000); // Exponential backoff
    }
  }
}
```

## Related Documentation

- [ARCHITECTURE.md](ARCHITECTURE.md) - Overall system design
- [DATABASE_SCHEMA.md](DATABASE_SCHEMA.md) - Complete schema reference
- [IMPLEMENTATION_ROADMAP.md](IMPLEMENTATION_ROADMAP.md) - Phased development plan
