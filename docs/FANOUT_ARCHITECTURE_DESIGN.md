# Fan-Out Architecture: Design Decisions

**Date**: 2025-10-15
**Topic**: How notifications fan out from webhooks

---

## ü§î The Question

**If a webhook creates a notification job, how do all the notifiers use it?**

Two possible architectures:

### **Option A: Parent Notification Handler (Coordinator)**
```
webhook-received job
         ‚îÇ
         ‚îú‚îÄ‚Üí scan-movie job
         ‚îî‚îÄ‚Üí notify job (PARENT)
                 ‚îÇ
                 ‚îú‚îÄ‚Üí Check kodi config ‚Üí Notify Kodi
                 ‚îú‚îÄ‚Üí Check discord config ‚Üí Notify Discord
                 ‚îî‚îÄ‚Üí Check pushover config ‚Üí Notify Pushover
```

One job, one handler, multiple notifications inside.

### **Option B: Multiple Specific Notification Jobs (Fan-Out)**
```
webhook-received job
         ‚îÇ
         ‚îú‚îÄ‚Üí scan-movie job
         ‚îú‚îÄ‚Üí notify-kodi job
         ‚îú‚îÄ‚Üí notify-discord job
         ‚îî‚îÄ‚Üí notify-pushover job
```

Multiple jobs, each job removed after completion.

---

## ‚úÖ **Recommended: Option B (Multiple Specific Jobs)**

### Why Option B is Better

#### **1. Isolation & Failure Independence**
```
If Kodi notification fails:
  ‚ùå Option A: Entire notify job fails ‚Üí retry ALL notifications
  ‚úÖ Option B: Only notify-kodi job retries ‚Üí others succeeded

Real scenario:
- Kodi server offline ‚Üí notify-kodi job retries
- Discord notification succeeded ‚Üí already removed from queue
- Pushover notification succeeded ‚Üí already removed from queue
```

#### **2. Independent Retry Logic**
```typescript
// Option B: Each notifier has its own retry config
await jobQueue.addJob({
  type: 'notify-kodi',
  max_retries: 3,  // Kodi flaky, retry more
  payload: {...}
});

await jobQueue.addJob({
  type: 'notify-discord',
  max_retries: 1,  // Discord reliable, retry less
  payload: {...}
});

await jobQueue.addJob({
  type: 'notify-pushover',
  max_retries: 2,
  payload: {...}
});
```

#### **3. Observability**
```
Job History:
‚úÖ [notify-kodi]     - completed - 500ms
‚úÖ [notify-discord]  - completed - 200ms
‚ùå [notify-pushover] - failed - "API key invalid"

vs.

‚ùå [notify] - failed - "One of the notifications failed" (which one??)
```

#### **4. Conditional Execution**
```typescript
// Webhook handler decides which jobs to create
const config = await getNotificationConfig();

if (config.kodi.enabled) {
  await jobQueue.addJob({ type: 'notify-kodi', ... });
}

if (config.discord.enabled) {
  await jobQueue.addJob({ type: 'notify-discord', ... });
}

// Don't create jobs for disabled services!
```

**Option A would need to check inside the handler:**
```typescript
async handleNotify(job) {
  // Check all configs inside handler
  if (kodiEnabled) await notifyKodi();
  if (discordEnabled) await notifyDiscord();
  // Handler becomes complex coordinator
}
```

#### **5. Priority Differences**
```typescript
// Media players more important than user notifications
await jobQueue.addJob({
  type: 'notify-kodi',
  priority: 5,  // NORMAL (critical for library refresh)
  payload: {...}
});

await jobQueue.addJob({
  type: 'notify-discord',
  priority: 7,  // LOWER (nice-to-have)
  payload: {...}
});
```

#### **6. Parallelization**
```
Option B: All notification jobs picked at once (if workers available)
‚îú‚îÄ Worker 1: Processing notify-kodi
‚îú‚îÄ Worker 2: Processing notify-discord
‚îî‚îÄ Worker 3: Processing notify-pushover

Option A: Single notify job blocks one worker
‚îî‚îÄ Worker 1: Processing notify (sequential inside)
```

---

## üèóÔ∏è **Implementation: Fan-Out Pattern**

### Webhook Handler (Producer)

```typescript
async handleWebhookReceived(job: Job): Promise<void> {
  const { source, eventType, movie } = job.payload;

  logger.info('[JobHandlers] Processing webhook', {
    service: 'JobHandlers',
    handler: 'handleWebhookReceived',
    jobId: job.id,
    source,
    eventType
  });

  // Log to activity_log
  await logActivity('webhook', source, eventType, job.payload);

  // Fan out based on event type
  if (eventType === 'Download') {
    // 1. Create scan job
    await this.jobQueue.addJob({
      type: 'scan-movie',
      priority: 2, // HIGH
      payload: {
        moviePath: movie.folderPath,
        tmdbId: movie.tmdbId,
        title: movie.title,
        year: movie.year
      },
      max_retries: 3
    });

    // 2. Fan out to notification jobs
    await this.createNotificationJobs('movie.downloaded', {
      movieId: movie.id,
      title: movie.title,
      year: movie.year
    });

    logger.info('[JobHandlers] Webhook fan-out complete', {
      jobId: job.id,
      eventType,
      jobsCreated: ['scan-movie', 'notifications']
    });
  }
}

/**
 * Create notification jobs for all enabled services
 */
private async createNotificationJobs(
  event: string,
  context: any
): Promise<void> {
  const config = await this.getNotificationConfig();

  // Only create jobs for enabled services
  const jobsCreated: string[] = [];

  // Kodi notification (media player refresh)
  if (config.kodi?.enabled) {
    await this.jobQueue.addJob({
      type: 'notify-kodi',
      priority: 5, // NORMAL
      payload: { event, context },
      max_retries: 3 // Retry if Kodi offline
    });
    jobsCreated.push('notify-kodi');
  }

  // Jellyfin notification (media player refresh)
  if (config.jellyfin?.enabled) {
    await this.jobQueue.addJob({
      type: 'notify-jellyfin',
      priority: 5,
      payload: { event, context },
      max_retries: 3
    });
    jobsCreated.push('notify-jellyfin');
  }

  // Discord notification (user notification)
  if (config.discord?.enabled) {
    await this.jobQueue.addJob({
      type: 'notify-discord',
      priority: 7, // LOWER (nice-to-have)
      payload: { event, context },
      max_retries: 1 // Don't spam Discord
    });
    jobsCreated.push('notify-discord');
  }

  // Pushover notification (user notification)
  if (config.pushover?.enabled) {
    await this.jobQueue.addJob({
      type: 'notify-pushover',
      priority: 7,
      payload: { event, context },
      max_retries: 1
    });
    jobsCreated.push('notify-pushover');
  }

  logger.info('[JobHandlers] Notification jobs created', {
    event,
    jobsCreated
  });
}
```

### Individual Notifier Handlers (Consumers)

```typescript
/**
 * Notify Kodi media players
 */
async handleNotifyKodi(job: Job): Promise<void> {
  logger.info('[JobHandlers] Processing Kodi notification', {
    service: 'JobHandlers',
    handler: 'handleNotifyKodi',
    jobId: job.id
  });

  const { event, context } = job.payload;

  // Get all Kodi groups
  const kodiGroups = await this.getMediaPlayerGroups('kodi');

  if (kodiGroups.length === 0) {
    logger.warn('[JobHandlers] No Kodi groups configured', {
      jobId: job.id
    });
    return; // Job completes (no-op)
  }

  // Notify each group
  for (const group of kodiGroups) {
    try {
      await this.notificationService.notifyKodi(group.id, event, context);
      logger.info('[JobHandlers] Kodi group notified', {
        jobId: job.id,
        groupId: group.id,
        groupName: group.name
      });
    } catch (error: any) {
      logger.error('[JobHandlers] Failed to notify Kodi group', {
        jobId: job.id,
        groupId: group.id,
        error: error.message
      });
      // Don't throw - continue with other groups
      // If ALL groups fail, throw at the end
    }
  }
}

/**
 * Notify Discord webhook
 */
async handleNotifyDiscord(job: Job): Promise<void> {
  logger.info('[JobHandlers] Processing Discord notification', {
    service: 'JobHandlers',
    handler: 'handleNotifyDiscord',
    jobId: job.id
  });

  const { event, context } = job.payload;
  const config = await this.getNotificationConfig('discord');

  // Format message based on event
  let message: string;
  if (event === 'movie.downloaded') {
    message = `üé¨ **${context.title}** (${context.year}) has been downloaded!`;
  } else if (event === 'movie.upgraded') {
    message = `‚¨ÜÔ∏è **${context.title}** has been upgraded to better quality!`;
  } else {
    message = `üì¢ Event: ${event}`;
  }

  // Send to Discord
  await this.notificationService.sendDiscordWebhook(
    config.webhookUrl,
    message
  );

  logger.info('[JobHandlers] Discord notified', {
    jobId: job.id,
    event
  });
}

/**
 * Notify Pushover
 */
async handleNotifyPushover(job: Job): Promise<void> {
  logger.info('[JobHandlers] Processing Pushover notification', {
    service: 'JobHandlers',
    handler: 'handleNotifyPushover',
    jobId: job.id
  });

  const { event, context } = job.payload;
  const config = await this.getNotificationConfig('pushover');

  // Format notification
  const notification = {
    token: config.apiToken,
    user: config.userKey,
    title: 'Metarr',
    message: `${context.title} (${context.year}) downloaded`,
    priority: event === 'movie.downloaded' ? 0 : -1
  };

  await this.notificationService.sendPushoverNotification(notification);

  logger.info('[JobHandlers] Pushover notified', {
    jobId: job.id,
    event
  });
}
```

---

## üîÑ **Job Lifecycle: Completed = Removed**

### Your Observation: "Once completed, job is removed"

**‚úÖ Correct!** This is the design we implemented:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  job_queue  ‚îÇ  status = 'pending'
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îÇ pickNextJob()
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  job_queue  ‚îÇ  status = 'processing'
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îÇ completeJob()
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ job_history ‚îÇ  status = 'completed'  ‚Üê MOVED HERE
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îî‚îÄ REMOVED from job_queue
```

**Why?**
- ‚úÖ Active queue only contains work to be done
- ‚úÖ Completed jobs archived to history
- ‚úÖ Fast queries (no filtering completed jobs)
- ‚úÖ Clean separation (queue vs audit trail)

**Industry Standard**: This matches **BullMQ**, **Celery**, **AWS SQS**

---

## ‚è∞ **Scheduled Tasks: Two Approaches**

### Your Question: "Cron that produces jobs OR job that's never removed?"

Let's compare both approaches:

### **Option 1: External Cron Produces Jobs** (Current)

```typescript
class FileScannerScheduler {
  start() {
    // Every night at 3 AM, CREATE a job
    cron.schedule('0 3 * * *', async () => {
      await jobQueue.addJob({
        type: 'scheduled-file-scan',
        priority: 8,
        payload: { trigger: 'scheduler' }
      });
    });
  }
}
```

**Flow**:
```
FileScannerScheduler (cron: 0 3 * * *)
         ‚îÇ
         ‚îî‚îÄ‚Üí Creates job at 3 AM
                 ‚îÇ
                 ‚ñº
           [scheduled-file-scan] job
                 ‚îÇ
                 ‚îÇ Processed
                 ‚ñº
           Moved to history (completed)
                 ‚îÇ
         Next day at 3 AM: New job created
```

**Pros**:
- ‚úÖ Simple: Scheduler creates jobs, queue processes them
- ‚úÖ Consistent: Scheduled jobs follow same queue logic
- ‚úÖ Observable: Job history shows every execution
- ‚úÖ Flexible: Easy to change schedule (just restart app)

**Cons**:
- ‚ùå External dependency (cron library)
- ‚ùå Schedule not in database (can't change without restart)

---

### **Option 2: Persistent Recurring Jobs** (Alternative)

```sql
-- Add recurring columns to job_queue
ALTER TABLE job_queue ADD COLUMN recurring TEXT;      -- '0 3 * * *' or NULL
ALTER TABLE job_queue ADD COLUMN last_completed DATETIME;
ALTER TABLE job_queue ADD COLUMN next_run DATETIME;
```

```typescript
// Job stays in queue, never removed
async completeRecurringJob(jobId: number): Promise<void> {
  const job = await this.storage.getJob(jobId);

  if (job.recurring) {
    // Calculate next run time
    const nextRun = calculateNextRun(job.recurring); // Parse cron

    // Update job, don't remove
    await db.execute(
      `UPDATE job_queue
       SET status = 'pending',
           last_completed = CURRENT_TIMESTAMP,
           next_run = ?,
           updated_at = CURRENT_TIMESTAMP
       WHERE id = ?`,
      [nextRun, jobId]
    );

    // Archive to history (for audit)
    await this.archiveJobExecution(jobId);
  } else {
    // Normal job: Remove from queue
    await this.completeJob(jobId);
  }
}

// Picker skips recurring jobs until next_run
async pickNextJob(): Promise<Job | null> {
  const jobs = await db.query(
    `SELECT * FROM job_queue
     WHERE status = 'pending'
       AND (next_run IS NULL OR next_run <= CURRENT_TIMESTAMP)
     ORDER BY priority ASC, created_at ASC
     LIMIT 1`
  );
  // ...
}
```

**Flow**:
```
[scheduled-file-scan] job (recurring: '0 3 * * *')
         ‚îÇ
         ‚îÇ Processed at 3 AM
         ‚ñº
   status = 'pending'
   last_completed = 2025-10-15 03:00:00
   next_run = 2025-10-16 03:00:00
         ‚îÇ
         ‚îÇ (stays in queue, skipped until next_run)
         ‚îÇ
         ‚îÇ Next day at 3 AM
         ‚ñº
   Picked again, processed, next_run updated
```

**Pros**:
- ‚úÖ Schedule in database (can change without restart)
- ‚úÖ Job persistence (survives restarts)
- ‚úÖ No external cron dependency

**Cons**:
- ‚ùå More complex (need to calculate next_run, skip logic)
- ‚ùå Active queue cluttered with sleeping jobs
- ‚ùå Risk of accidental deletion (if you delete the job, schedule gone)

---

## üéØ **Recommendation**

### **Use Option 1: External Cron (Current Approach)**

**Why?**
1. **Simpler**: Scheduler creates jobs, queue processes them
2. **Cleaner**: Active queue only contains ready-to-process jobs
3. **Consistent**: Scheduled jobs follow same lifecycle as other jobs
4. **Observable**: Every execution logged in job_history

**Industry Examples**:
- ‚úÖ **Celery Beat**: External scheduler creates periodic tasks
- ‚úÖ **Kubernetes CronJobs**: External scheduler creates pods
- ‚úÖ **AWS EventBridge**: External scheduler triggers Lambda

### **When to Use Option 2: Persistent Recurring Jobs**

Use this if you need:
- Dynamic schedule changes without restart
- User-defined recurring jobs (e.g., "Export report every Monday")
- Multi-tenant with per-tenant schedules

**Industry Examples**:
- ‚úÖ **BullMQ**: Repeatable jobs with cron syntax
- ‚úÖ **APScheduler**: Persistent job store
- ‚úÖ **Sidekiq-Cron**: Redis-backed recurring jobs

---

## üìä **Architecture Comparison**

### **Fan-Out: Parent Handler vs Multiple Jobs**

| Aspect | Parent Handler (Option A) | Multiple Jobs (Option B) |
|--------|--------------------------|--------------------------|
| **Failure Isolation** | ‚ùå One failure = retry all | ‚úÖ Independent retry |
| **Retry Logic** | ‚ùå Same for all notifiers | ‚úÖ Per-notifier config |
| **Observability** | ‚ùå One job entry | ‚úÖ Separate history per notifier |
| **Parallelization** | ‚ùå Sequential inside handler | ‚úÖ Parallel processing |
| **Priority** | ‚ùå Same for all | ‚úÖ Different per notifier |
| **Conditional Execution** | ‚ö†Ô∏è Check inside handler | ‚úÖ Don't create job if disabled |
| **Complexity** | ‚ö†Ô∏è Handler is coordinator | ‚úÖ Simple handlers |

**Winner**: Option B (Multiple Jobs) ‚úÖ

---

### **Scheduled Tasks: Cron vs Persistent**

| Aspect | External Cron (Option 1) | Persistent Jobs (Option 2) |
|--------|-------------------------|---------------------------|
| **Simplicity** | ‚úÖ Simple | ‚ùå Complex (next_run calc) |
| **Queue Clutter** | ‚úÖ Clean queue | ‚ùå Sleeping jobs in queue |
| **Dynamic Schedules** | ‚ùå Needs restart | ‚úÖ Change in DB |
| **Observability** | ‚úÖ Every run in history | ‚úÖ Every run in history |
| **Risk** | ‚úÖ Can't accidentally delete | ‚ùå Delete job = lose schedule |
| **Industry Standard** | ‚úÖ Celery, K8s, AWS | ‚úÖ BullMQ, APScheduler |

**Winner**: Option 1 (External Cron) for simplicity ‚úÖ
**Use Option 2** if you need dynamic schedules

---

## ‚úÖ **Final Recommendation**

### **Fan-Out Architecture**:
```
webhook-received job
         ‚îÇ
         ‚îú‚îÄ‚Üí scan-movie job
         ‚îú‚îÄ‚Üí notify-kodi job       ‚Üê Separate jobs
         ‚îú‚îÄ‚Üí notify-discord job    ‚Üê Separate jobs
         ‚îî‚îÄ‚Üí notify-pushover job   ‚Üê Separate jobs

Each job completes ‚Üí removed ‚Üí archived to history
```

### **Scheduled Tasks**:
```
FileScannerScheduler (external cron)
         ‚îÇ
         ‚îî‚îÄ‚Üí Creates job at scheduled time
                 ‚îÇ
                 ‚ñº
           [scheduled-file-scan] job
                 ‚îÇ
                 ‚îÇ Processed
                 ‚ñº
           Completed ‚Üí removed ‚Üí archived

Next scheduled time: New job created
```

---

## üöÄ **Implementation Summary**

**What to implement**:
1. ‚úÖ Multiple specific notification jobs (not parent)
2. ‚úÖ Webhook handler fans out to multiple jobs
3. ‚úÖ Each notifier checks its own config
4. ‚úÖ Jobs removed after completion (archived to history)
5. ‚úÖ Keep external cron schedulers (FileScannerScheduler, etc.)

**What NOT to implement**:
1. ‚ùå Parent notification handler (coordinator)
2. ‚ùå Persistent recurring jobs in queue

**Result**: Clean, simple, scalable architecture matching industry best practices! ‚úÖ
